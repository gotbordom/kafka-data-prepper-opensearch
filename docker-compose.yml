services:
  zk-1:
    image: confluentinc/cp-zookeeper:latest
    restart: always
    container_name: zk-1
    hostname: zk-1
    ports:
      - "12181:12181"
    volumes:
      - data-zk-log-1:/var/lib/zookeeper/log
      - data-zk-data-1:/var/lib/zookeeper/data
    networks:
      - confluent
    environment:
      - ZOOKEEPER_SERVER_ID=1
      - ZOOKEEPER_CLIENT_PORT=12181
      - ZOOKEEPER_TICK_TIME=2000
      - ZOOKEEPER_INIT_LIMIT=5
      - ZOOKEEPER_SYNC_LIMIT=2
      - ZOOKEEPER_SERVERS=zk-1:2888:3888

  kafka-1:
    image: confluentinc/cp-kafka:latest
    restart: always
    container_name: kafka-1
    hostname: kafka-1
    ports:
      - "19092:19092"
      - "19093:19093"
    networks:
      - confluent
    volumes:
      - data-kafka-1:/var/lib/kafka/data
      - ./secrets/kafka-1-creds:/etc/kafka/secrets
    environment:
      KAFKA_BROKER_ID: 101
      KAFKA_ZOOKEEPER_CONNECT: zk-1:12181
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      #KAFKA_METRIC_REPORTERS: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
      #CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: "kafka-1:9092,kafka-2:9092,kafka-3:9092"
      #KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19092,BROKER://0.0.0.0:9092
      #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:19092,BROKER://kafka-1:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19092,SSL://0.0.0.0:19093,BROKER://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:19092,SSL://192.168.240.1:19093,BROKER://kafka-1:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,SSL:SSL,BROKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_SSL_KEYSTORE_FILENAME: kafka.kafka-1.keystore.pkcs12
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka-1_keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: kafka-1_ssl_key_creds
      #KAFKA_SSL_TRUSTSTORE_FILENAME: kafka.kafka-1.truststore.pkcs12
      #KAFKA_SSL_TRUSTSTORE_CREDENTIALS: kafka-1_truststore_creds
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "HTTPS"
      #KAFKA_SSL_CLIENT_AUTH: "required"

  data-prepper-1:
    image: opensearchproject/data-prepper:latest
    container_name: data-prepper-1
    ports:
      - "4900:4900"
    networks:
      - confluent
    volumes:
      - ./secrets/kafka-1-creds/client-creds:/etc/kafka/secrets
      - ./pipelines.yaml:/usr/share/data-prepper/pipelines/pipelines.yaml

  opensearch-node-1:
    # This is also the hostname of the container within the Docker network (i.e. https://opensearch-node1/)
    image: opensearchproject/opensearch:latest
    container_name: opensearch-node-1
    environment:
      - cluster.name=opensearch-cluster # Name the cluster
      - node.name=opensearch-node-1 # Name the node that will run in this container
      - discovery.seed_hosts=opensearch-node-1,opensearch-node-2 # Nodes to look for when discovering the cluster
      - cluster.initial_cluster_manager_nodes=opensearch-node-1,opensearch-node-2 # Nodes eligibile to serve as cluster manager
      - bootstrap.memory_lock=true # Disable JVM heap memory swapping
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # Set min and max JVM heap sizes to at least 50% of system RAM
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=${OPENSEARCH_INITIAL_ADMIN_PASSWORD} # Sets the demo admin user password when using demo configuration (for OpenSearch 2.12 and later)
    ulimits:
      memlock:
        soft: -1 # Set memlock to unlimited (no soft or hard limit)
        hard: -1
      nofile:
        soft: 65536 # Maximum number of open files for the opensearch user - set to at least 65536
        hard: 65536
    volumes:
      - opensearch-data-1:/usr/share/opensearch/data # Creates volume called opensearch-data-1 and mounts it to the container
    ports:
      - 9200:9200 # REST API
      - 9600:9600 # Performance Analyzer
    networks:
      - confluent # All of the containers will join the same Docker bridge network
  opensearch-node-2:
    image: opensearchproject/opensearch:latest # This should be the same image used for opensearch-node-1 to avoid issues
    container_name: opensearch-node-2
    environment:
      - cluster.name=opensearch-cluster
      - node.name=opensearch-node-2
      - discovery.seed_hosts=opensearch-node-1,opensearch-node-2
      - cluster.initial_cluster_manager_nodes=opensearch-node-1,opensearch-node-2
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=${OPENSEARCH_INITIAL_ADMIN_PASSWORD}
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - opensearch-data-2:/usr/share/opensearch/data
    networks:
      - confluent
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:latest # Make sure the version of opensearch-dashboards matches the version of opensearch installed on other nodes
    container_name: opensearch-dashboards
    ports:
      - 5601:5601 # Map host port 5601 to container port 5601
    expose:
      - "5601" # Expose port 5601 for web access to OpenSearch Dashboards
    environment:
      OPENSEARCH_HOSTS: '["https://opensearch-node-1:9200","https://opensearch-node-2:9200"]' # Define the OpenSearch nodes that OpenSearch Dashboards will query
    networks:
      - confluent

volumes:
  data-zk-log-1:
  data-zk-data-1:
  data-kafka-1:
  opensearch-data-1:
  opensearch-data-2:


networks:
  confluent:
